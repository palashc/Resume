\section{Key Projects}

\cventry
{Aug. 2016\\--Nov. 2016}
{Densecap with NMS Convenet}
{Course project under Dr. Gaurav Sharma}
{}
{}
{
	\begin{itemize}
		\item {Analyzed the work ``DenseCap'' by Andrej Karpathy et. al. by experimenting with the parameters and design choices of Fully Convolutional Localization Network on Visual Genome dataset.}
		\item To discard the original test-time non-maximum suppression, we used trainable spatial suppression layer from the work ``A convnet for non-maximum suppression'' by Jan Hosang et. al. This enhanced the \textbf{mAP} of densecap from \textbf{5.698 to 5.76}.\hfill( \href{https://www.dropbox.com/s/5jidhqmthy9ks06/cs698-final-report-extended.pdf?dl=0}{report \ExternalLink}, \href{https://www.dropbox.com/s/byn2z4o4yiwf00b/CS698\%20Final\%20PPT.pdf?dl=0}{pres \ExternalLink}
		)
	\end{itemize}
}

\cventry
	{Jan. 2015\\--Apr. 2015}
	{Multiple Kernel Learning}
	{Undergraduate project under Dr. Harish Karnick}
	{}{}
	{
		\begin{itemize}
			 \item {Studied Relative Reproducing Kernel Hilbert space, Multiple Kernel Learning, and Hierarchical Kernel Learning.}
			 %\item {}
			 \item {Implemented \textbf{Simple MKL} to study the effects of the linear combination of distinct kernels on SVM classifier. Classification task was done on Caltech multiclass object classification dataset using SURF and convolutional deep-net features(pre-trained BVLC GoogleNet model). \hfill (\href{https://www.dropbox.com/s/dg987vl0zdfh6kj/cs396-graduate-project.pdf?dl=0}{report \ExternalLink})	}
		\end{itemize}
	}
	
\cventry
	{Jan. 2017\\--May 2017}
	{Poisson Matrix Factorization}
	{Course project under Dr. Piyush Rai}
	{}{}
	%{} % Date(s)
	{
		\begin{itemize}
			\item {Studied various models for Bayesian Recommender Systems including Poisson Matrix Factorization, Hierarchical Poisson Matrix Factorization, Bayesian Non-parametric Poisson Matrix Factorization}
			\item {Implemented and compared the performance of the three models on MovieLens 1M dataset. }
			\item {Also analyzed the effect of latent dimension on the models. Learnt the use of auxiliary variables in variational inference to make the models locally conjugate and facilitate inference \hfill (\href{https://www.dropbox.com/s/a5gn52k0ggf8m5w/poisson-matrix-factorization.pdf?dl=0}{report \ExternalLink})}
		\end{itemize}
	}

\cventry
	{Aug. 2016\\--Nov. 2016}
	{Automatic Abstract Generation for Research Papers}
	{Course project under Dr. Harish Karnick}
	%{\textbf{}} % Date(s)
	{}{}
	{
		\begin{itemize}
			\item {
				The important sentences are extracted from the paper and fed to an abstractive model which outputs the final summary of the paper. 	For extractive summarization, we experimented with word frequency based scores, text rank, and latent semantic analysis using ROGUE as an evaluation metric.
			}
			\item {
				To generate the final abstract, we implemented RNN encoder-decoder network using Keras library. \hfill (\href{https://www.dropbox.com/s/h5jqpm20l8bhan6/G4-FinalReport.pdf?dl=0}{report \ExternalLink})
			}
		\end{itemize}
	}	

\cventry
	{Aug. 2016\\--Nov. 2016}
	{Low-rank model for neural networks}
	{Course project under Dr. Purushottam Kar}
	%{\textbf{}	}
	{}{}
	{
		\begin{itemize}
			\item { 
				Implemented a module for decomposing the input weight matrix into a low rank and a sparse matrix.
			}
			\item { 
				The module is based on the work - ``Robust PCA problem via outlier pursuit'' which finds the low-dimensional subspace approximation to high dimensional points after eliminating corruptions. \hfill (\href{https://www.dropbox.com/s/wb51nni96m6s1nr/Final\%20Project\%20Report.pdf?dl=0}{report \ExternalLink})
			}
		\end{itemize}
	}

\cventry
	{Jan.2016\\--Aug. 2016}
	{Object(Pedestrian/Two-Wheeler/Three-Wheeler) Identification in Surveillance Videos}
	{Course project under Dr. Harish Karnick}
%	{
%		\textbf{}, 
%		\textbf{}	
%	}
	{}{}
	{
		\begin{itemize}
			\item {Experimented with object proposal methods (Morphological, Selective Search) and feature extractors (SURF, ConvNets) for detection and classification.}
			\item {Used decision tree, random forest and SVM (OVR and OVO) classifiers to predict labels \hfill (\href{https://github.com/submagr/MLT-Classifier}{code \ExternalLink}, \href{https://www.dropbox.com/s/sh69si90hl7mtxr/MLTProjectReport.pdf?dl=0}{report \ExternalLink})}
		\end{itemize}
	}